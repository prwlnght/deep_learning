{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import shutil\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join('..', '..', 'bigyan', 'artgen.bigyan', 'data', 'cartoonset100k')\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_directory= os.path.join('C:', 'Users', 'paudy' , 'tmp_images', 'deep_learning_tmp', 'cartoonset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model():\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, (2, 2), activation='relu', input_shape=(256, 256, 3)), # no parameters\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3), \n",
    "    keras.layers.Conv2D(64, 3, (2, 2), activation='relu'), # no parameters\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(128, 5, (2, 2), activation='relu'), # no parameters\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(256, 5, (2, 2), activation='relu'), # no parameters\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10), # no activation! \n",
    "    keras.layers.Softmax()\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "     metrics=['accuracy'] #the metric that is reported\n",
    "     )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_labels_folder(img_files, label_files, feature_name, cache_directory, label_idx_dict, reset_images=False, reuse_images=False):\n",
    "    \"\"\"\n",
    "    copies images to the feature name subfolder in the cache directory\n",
    "    images are copied into sub directories according the the lablel \n",
    "    \"\"\"\n",
    "    if not os.path.exists(cache_directory):\n",
    "        raise Exception(f'{cache_directory} does not exist')\n",
    "    feature_dir = os.path.join(cache_directory, feature_name)\n",
    "    \n",
    "    if os.path.exists(feature_dir):\n",
    "        if reset_images:\n",
    "            print(f'{feature_dir} does not exist, creating ... ')\n",
    "            shutil.rmtree(feature_dir)\n",
    "            os.mkdir(feature_dir)\n",
    "        else:\n",
    "            if reuse_images:\n",
    "                #nothing to do \n",
    "                return feature_dir\n",
    "            else:\n",
    "                raise Exception(f'Invalid Arguments, {feature_dir} already exists, set reset_images to True to reset for {feature_name}')\n",
    "    else:\n",
    "        print(f'{feature_dir} does not exist, creating ... ')\n",
    "        os.mkdir(feature_dir)\n",
    "     \n",
    "    feature_idx = label_idx_dict.get(feature_name, None)\n",
    "        \n",
    "    for img_file, label_file in list(zip(img_files, label_files)):\n",
    "        label = pd.read_csv(label_file, header=None).loc[feature_idx][1]\n",
    "        label_dir = os.path.join(feature_dir, str(label))\n",
    "        if not os.path.exists(label_dir):\n",
    "            print(f'{label_dir} does not exist, creating ... ')\n",
    "            os.mkdir(label_dir)\n",
    "        try:\n",
    "            shutil.copy(img_file, label_dir)\n",
    "        except:\n",
    "            pass\n",
    "    return feature_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_idx_dicts(label_file):\n",
    "    idx_label_dict = pd.read_csv(label_file, header=None)[0].to_dict()\n",
    "    label_idx_dict = {v:k for k, v in idx_label_dict.items()}\n",
    "    return idx_label_dict, label_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, fnames_ in os.walk(data_dir):\n",
    "    all_file_paths = [os.path.join(root, fname) for fname in fnames_]\n",
    "img_files = [x for x in all_file_paths if x.endswith('.png')]\n",
    "label_files = [x for x in all_file_paths if x.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_label_dict, label_idx_dict = get_feature_idx_dicts(label_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eye_angle': 0,\n",
       " 'eye_lashes': 1,\n",
       " 'eye_lid': 2,\n",
       " 'chin_length': 3,\n",
       " 'eyebrow_weight': 4,\n",
       " 'eyebrow_shape': 5,\n",
       " 'eyebrow_thickness': 6,\n",
       " 'face_shape': 7,\n",
       " 'facial_hair': 8,\n",
       " 'hair': 9,\n",
       " 'eye_color': 10,\n",
       " 'face_color': 11,\n",
       " 'hair_color': 12,\n",
       " 'glasses': 13,\n",
       " 'glasses_color': 14,\n",
       " 'eye_slant': 15,\n",
       " 'eyebrow_width': 16,\n",
       " 'eye_eyebrow_distance': 17}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_consider = ['hair_color', 'face_color', 'face_shape']\n",
    "features_to_consider = ['eyebrow_thickness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyebrow_thickness\n",
      "Created training dir: C:Users\\paudy\\tmp_images\\deep_learning_tmp\\cartoonset\\eyebrow_thickness\n",
      "Found 10000 files belonging to 4 classes.\n",
      "Using 8000 files for training.\n",
      "Found 10000 files belonging to 4 classes.\n",
      "Using 2000 files for validation.\n",
      "Epoch 1/20\n",
      "  2/250 [..............................] - ETA: 3:18 - loss: 2.3357 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1890s vs `on_train_batch_end` time: 0.9724s). Check your callbacks.\n",
      "250/250 [==============================] - 119s 475ms/step - loss: 2.2106 - accuracy: 0.2447 - val_loss: 2.1962 - val_accuracy: 0.2585\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 116s 463ms/step - loss: 2.1996 - accuracy: 0.2522 - val_loss: 2.2069 - val_accuracy: 0.2455\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 109s 437ms/step - loss: 2.1870 - accuracy: 0.2649 - val_loss: 2.2124 - val_accuracy: 0.2410\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 123s 492ms/step - loss: 2.1753 - accuracy: 0.2750 - val_loss: 2.1732 - val_accuracy: 0.2780\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 126s 502ms/step - loss: 2.1387 - accuracy: 0.3137 - val_loss: 2.1294 - val_accuracy: 0.3205\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 123s 493ms/step - loss: 2.0899 - accuracy: 0.3600 - val_loss: 2.0877 - val_accuracy: 0.3605\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 125s 498ms/step - loss: 2.0571 - accuracy: 0.3931 - val_loss: 2.0669 - val_accuracy: 0.3795\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 118s 472ms/step - loss: 2.0361 - accuracy: 0.4145 - val_loss: 2.0164 - val_accuracy: 0.4375\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 2.0181 - accuracy: 0.4329 - val_loss: 2.0019 - val_accuracy: 0.4520\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 1.9977 - accuracy: 0.4593 - val_loss: 1.9798 - val_accuracy: 0.4740\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 1.9837 - accuracy: 0.4704 - val_loss: 1.9915 - val_accuracy: 0.4575\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 1.9796 - accuracy: 0.4736 - val_loss: 2.0248 - val_accuracy: 0.4180\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 1.9759 - accuracy: 0.4787 - val_loss: 1.9421 - val_accuracy: 0.5140\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 1.9560 - accuracy: 0.5000 - val_loss: 1.9475 - val_accuracy: 0.5110\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 1.9497 - accuracy: 0.5066 - val_loss: 1.9562 - val_accuracy: 0.4930\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 1.9507 - accuracy: 0.5040 - val_loss: 1.9585 - val_accuracy: 0.4955\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 1.9393 - accuracy: 0.5159 - val_loss: 1.9227 - val_accuracy: 0.5300\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 94s 376ms/step - loss: 1.9274 - accuracy: 0.5286 - val_loss: 1.9189 - val_accuracy: 0.5380\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 1.9190 - accuracy: 0.5365 - val_loss: 1.9287 - val_accuracy: 0.5200\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 1.9216 - accuracy: 0.5314 - val_loss: 1.9400 - val_accuracy: 0.5165\n",
      "63/63 [==============================] - 8s 124ms/step - loss: 1.9400 - accuracy: 0.5165\n",
      "[1.9399964809417725, 0.5164999961853027]\n",
      "{'eyebrow_thickness': 0.5163690476190477}\n"
     ]
    }
   ],
   "source": [
    "base_logdir = os.path.join('logs')\n",
    "base_modelsdir = os.path.join('models')\n",
    "n_epochs = 20\n",
    "feature_counter = 2\n",
    "validation_metrics = {}\n",
    "for feature_name in features_to_consider:\n",
    "    print(feature_name)\n",
    "    training_dir = copy_images_to_labels_folder(img_files, label_files, feature_name, cache_directory, label_idx_dict, reuse_images=True)\n",
    "    print(f'Created training dir: {training_dir}')\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        training_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "        class_names=None,\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        image_size=(256, 256),\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        validation_split=.2,\n",
    "        subset=\"training\",\n",
    "        interpolation=\"bilinear\",\n",
    "        follow_links=False,\n",
    "        )\n",
    "    validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    training_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=.2,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    )\n",
    "    model = build_and_compile_model()\n",
    "    this_logdir = os.path.join(base_logdir, feature_name)\n",
    "    if not os.path.exists(this_logdir):\n",
    "        os.mkdir(this_logdir)\n",
    "    logdir = os.path.join(this_logdir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "    model.fit(train_dataset,  epochs=n_epochs, validation_data=validation_dataset, callbacks=[tensorboard_callback])\n",
    "    print(model.evaluate(validation_dataset))  \n",
    "    this_modeldir = os.path.join(base_modelsdir, feature_name)\n",
    "    if not os.path.exists(this_modeldir):\n",
    "        os.mkdir(this_modeldir)\n",
    "    modelpath = os.path.join(this_modeldir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+f'epochs-{str(n_epochs)}.h5')\n",
    "    model.save(modelpath, overwrite=True, include_optimizer=True)\n",
    "    loaded_model = keras.models.load_model(modelpath)\n",
    "    acc_score_sum = 0\n",
    "    iterations = 0\n",
    "    for x, y in validation_dataset:\n",
    "        acc_score_sum += accuracy_score(y, np.argmax(loaded_model.predict(x), axis=1))\n",
    "        iterations+= 1\n",
    "    validation_metrics[feature_name] = acc_score_sum/iterations\n",
    "    print(validation_metrics)\n",
    "    feature_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  2/250 [..............................] - ETA: 2:36 - loss: 1.8663 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1620s vs `on_train_batch_end` time: 0.9110s). Check your callbacks.\n",
      "250/250 [==============================] - 104s 414ms/step - loss: 1.9315 - accuracy: 0.5244 - val_loss: 1.9357 - val_accuracy: 0.5165\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 1.9094 - accuracy: 0.5480 - val_loss: 2.1239 - val_accuracy: 0.3320\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 1.9096 - accuracy: 0.5458 - val_loss: 1.8989 - val_accuracy: 0.5555\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 1.9012 - accuracy: 0.5533 - val_loss: 2.1133 - val_accuracy: 0.3455\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 97s 387ms/step - loss: 1.9001 - accuracy: 0.5567 - val_loss: 1.8912 - val_accuracy: 0.5625\n",
      "Epoch 6/20\n",
      " 81/250 [========>.....................] - ETA: 1:00 - loss: 1.8974 - accuracy: 0.5606"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,  epochs=n_epochs, validation_data=validation_dataset, callbacks=[tensorboard_callback])\n",
    "print(model.evaluate(validation_dataset))  \n",
    "this_modeldir = os.path.join(base_modelsdir, feature_name)\n",
    "if not os.path.exists(this_modeldir):\n",
    "    os.mkdir(this_modeldir)\n",
    "modelpath = os.path.join(this_modeldir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+f'epochs-{str(n_epochs)}.h5')\n",
    "model.save(modelpath, overwrite=True, include_optimizer=True)\n",
    "loaded_model = keras.models.load_model(modelpath)\n",
    "acc_score_sum = 0\n",
    "iterations = 0\n",
    "for x, y in validation_dataset:\n",
    "    acc_score_sum += accuracy_score(y, np.argmax(loaded_model.predict(x), axis=1))\n",
    "    iterations+= 1\n",
    "validation_metrics[feature_name] = acc_score_sum/iterations\n",
    "print(validation_metrics)\n",
    "feature_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
